{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to write your code for problem 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D - Convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in problem 2, we have conveniently provided for your use code that loads, preprocesses, and deals with the uglies of the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data into Keras format\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.divide(x_train, 255)\n",
    "x_test = np.divide(x_test, 255)\n",
    "\n",
    "# Reshape the X data (add a channel dimension)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "x_test = x_test.reshape(tuple(list(x_test.shape) + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 0.1507 - acc: 0.9549 - val_loss: 0.0559 - val_acc: 0.9827\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0837 - acc: 0.9749 - val_loss: 0.0508 - val_acc: 0.9847\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0716 - acc: 0.9788 - val_loss: 0.0637 - val_acc: 0.9815\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 209s 3ms/step - loss: 0.0628 - acc: 0.9822 - val_loss: 0.0447 - val_acc: 0.9846\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.0572 - acc: 0.9833 - val_loss: 0.0417 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 210s 4ms/step - loss: 0.0551 - acc: 0.9843 - val_loss: 0.0462 - val_acc: 0.9870\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 209s 3ms/step - loss: 0.0506 - acc: 0.9850 - val_loss: 0.0413 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 210s 3ms/step - loss: 0.0506 - acc: 0.9854 - val_loss: 0.0430 - val_acc: 0.9878\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 210s 3ms/step - loss: 0.0455 - acc: 0.9869 - val_loss: 0.0437 - val_acc: 0.9872\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 210s 4ms/step - loss: 0.0448 - acc: 0.9873 - val_loss: 0.0448 - val_acc: 0.9889\n",
      "60000/60000 [==============================] - 47s 788us/step\n",
      "[0.015551200077058881, 0.99571666666666669]\n",
      "10000/10000 [==============================] - 8s 794us/step\n",
      "[0.044757800438810773, 0.9889]\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE CODE FOR THE FINAL MODEL WITH TEST ACCURACY AT LEAST 0.985\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "# Final model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(50, (3, 3), padding='same',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Count the number of parameters in the model\n",
    "model.count_params()\n",
    "\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "# Output training and test losses\n",
    "print(model.evaluate(x=x_train, y=y_train))\n",
    "print(model.evaluate(x=x_test, y=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.1089 - acc: 0.9680 - val_loss: 0.0556 - val_acc: 0.9817\n",
      "60000/60000 [==============================] - 45s 742us/step\n",
      "[0.039181514429821013, 0.98788333333333334]\n",
      "10000/10000 [==============================] - 7s 736us/step\n",
      "[0.055629211670020592, 0.98170000000000002]\n",
      "0.111111111111\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.1136 - acc: 0.9672 - val_loss: 0.0568 - val_acc: 0.9807\n",
      "60000/60000 [==============================] - 46s 770us/step\n",
      "[0.041157759057008664, 0.98753333333333337]\n",
      "10000/10000 [==============================] - 7s 728us/step\n",
      "[0.056798459928203371, 0.98070000000000002]\n",
      "0.222222222222\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 242s 4ms/step - loss: 0.1172 - acc: 0.9655 - val_loss: 0.0602 - val_acc: 0.9814\n",
      "60000/60000 [==============================] - 62s 1ms/step\n",
      "[0.042927125190803779, 0.98709999999999998]\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "[0.060193563663214447, 0.98140000000000005]\n",
      "0.333333333333\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 244s 4ms/step - loss: 0.1286 - acc: 0.9620 - val_loss: 0.0587 - val_acc: 0.9824\n",
      "60000/60000 [==============================] - 61s 1ms/step\n",
      "[0.045514737454920157, 0.98653333333333337]\n",
      "10000/10000 [==============================] - 9s 950us/step\n",
      "[0.05865200367269572, 0.98240000000000005]\n",
      "0.444444444444\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 241s 4ms/step - loss: 0.1424 - acc: 0.9579 - val_loss: 0.0681 - val_acc: 0.9789\n",
      "60000/60000 [==============================] - 67s 1ms/step\n",
      "[0.053639914274743447, 0.98406666666666665]\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "[0.068131367394421244, 0.97889999999999999]\n",
      "0.555555555556\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.1581 - acc: 0.9525 - val_loss: 0.0525 - val_acc: 0.9836\n",
      "60000/60000 [==============================] - 55s 914us/step\n",
      "[0.049856283165762821, 0.9851833333333333]\n",
      "10000/10000 [==============================] - 9s 912us/step\n",
      "[0.052526849704165941, 0.98360000000000003]\n",
      "0.666666666667\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 327s 5ms/step - loss: 0.1950 - acc: 0.9413 - val_loss: 0.0682 - val_acc: 0.9787\n",
      "60000/60000 [==============================] - 76s 1ms/step\n",
      "[0.065529408958895752, 0.98029999999999995]\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "[0.068170487205870448, 0.97870000000000001]\n",
      "0.777777777778\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 361s 6ms/step - loss: 0.2395 - acc: 0.9278 - val_loss: 0.0696 - val_acc: 0.9783\n",
      "60000/60000 [==============================] - 74s 1ms/step\n",
      "[0.070633233936317263, 0.97883333333333333]\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "[0.069583351073041561, 0.97829999999999995]\n",
      "0.888888888889\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.3747 - acc: 0.8838 - val_loss: 0.1131 - val_acc: 0.9665\n",
      "60000/60000 [==============================] - 55s 919us/step\n",
      "[0.11615070782086502, 0.96583333333333332]\n",
      "10000/10000 [==============================] - 9s 880us/step\n",
      "[0.1131480140235275, 0.96650000000000003]\n",
      "1.0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 0.1069 - acc: 0.9694 - val_loss: 0.0544 - val_acc: 0.9820\n",
      "60000/60000 [==============================] - 53s 889us/step\n",
      "[0.039002865583643631, 0.98843333333333339]\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "[0.054449354660883548, 0.98199999999999998]\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE CODE FOR DETERMINING THE TEST ACCURACY FOR THE TEN DROPOUT PROBABILITIES \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "def network(d):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(50, (3, 3), padding='same',\n",
    "                     input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Count the number of parameters in the model\n",
    "    model.count_params()\n",
    "\n",
    "    # For a multi-class classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model, for one epoch in batches of 32 samples\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=32,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "    # Output training and test losses\n",
    "    print(model.evaluate(x=x_train, y=y_train))\n",
    "    print(model.evaluate(x=x_test, y=y_test))\n",
    "    \n",
    "probabilities = np.linspace(0, 1, num = 10)\n",
    "for i in range(len(probabilities)):\n",
    "    print(probabilities[i])\n",
    "    network(probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
